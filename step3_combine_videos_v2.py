"""
Chapter Video Combiner  • 2025-07-24 (clean version)
────────────────────────────────────────────────────────────────────────────
Stitch the single-sentence videos generated by *multi_language_video_generator.py*
into **multiple videos per chapter**, with options:

1. Process a single chapter only.
2. Process a range of chapters (start–end).
3. Exclude specific sentence IDs.

Export is done in fixed-size chunks (default 10 clips per file):

    nufi_chapter_1_chunk_01.mp4
    nufi_chapter_1_chunk_02.mp4
    …

Robustness:
• Corrupt/missing clips are skipped with a warning (⚠).
• Every VideoFileClip is explicitly closed.

Tested with MoviePy 1.x. For MoviePy 2.x, update the import line as noted.
"""

from __future__ import annotations
import os, random, re, time
from pathlib import Path
from typing import List, Dict, Iterable
from moviepy.editor import VideoFileClip, concatenate_videoclips
# from moviepy import VideoFileClip, concatenate_videoclips  # ← for MoviePy 2.x

# ── USER SETTINGS ──────────────────────────────────────────────────────
LANGUAGE  = "Duala"         # Language
MODE      = "lecture"       # "lecture" or "homework"
ROOT      = Path(r"G:/My Drive/Data_Science/Resulam/Phrasebook_Audio_Video_Processing_production")
FPS       = 24
FFMPEG_THREADS_PER_JOB = 4
SHUFFLE_SEED = None
CHUNK_SIZE = 10

# Control which chapters to process
SINGLE_CHAPTER = None   # e.g., 12 → only Chapter 12
START_CHAPTER  = 27     # default = 1
END_CHAPTER    = 27     # None = until last chapter

# Excluded sentence IDs
EXCLUDED_SENTENCES = {
    1476,1477,1478,1479,1480,1481,1482,1483,
    1590,1607,1610,1614,1616,1621,1628,1629,
    1646,1647,1762,1763,2010
}

# ── FOLDER LAYOUT ──────────────────────────────────────────────────────
VIDEO_DIR  = ROOT / "Python_Scripts_Resulam_Phrasebooks_Audio_Processing"
VIDEO_PATTERN = "{lang_lower}_sentence_{id}.mp4"
OUTPUT_DIR = ROOT / "Chapter_Combined"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# ── HELPERS ────────────────────────────────────────────────────────────
def build_paths(lang: str, mode: str) -> Dict[str, Path]:
    lang_lower = lang.lower()
    out_dir = VIDEO_DIR / f"{lang.title()}/{mode.title()}"
    txt = ROOT / f"Languages/{lang}Phrasebook/{lang_lower}_english_french_phrasebook_sentences_list.txt"
    if not out_dir.exists():
        raise FileNotFoundError(f"Sentence-video folder not found: {out_dir}")
    if not txt.exists():
        raise FileNotFoundError(f"Cannot locate sentence list: {txt}")
    return {"lang_lower": lang_lower, "out_dir": out_dir, "sent_txt": txt}

def parse_chapters(txt_file: Path) -> Dict[int, List[int]]:
    """Return {chapter_number: [sentence_id,…]} preserving original order."""
    chapters: Dict[int, List[int]] = {}
    current = None
    with open(txt_file, encoding="utf-8") as fh:
        for ln in fh:
            if "|" not in ln:
                continue
            try:
                id_part, en_raw = ln.split(")", 1)
                sid = int(id_part.strip())
            except ValueError:
                continue
            english = en_raw.split("|", 1)[0].strip().lower()
            if english.startswith("chapter"):
                m = re.search(r"chapter\s+(\d+)", english)
                current = int(m.group(1)) if m else (current or 0) + 1
            if current is None:
                continue
            chapters.setdefault(current, []).append(sid)
    return chapters

def gather_clips(sentence_ids: Iterable[int], lang_lower: str, out_dir: Path) -> List[Path]:
    paths = [out_dir / VIDEO_PATTERN.format(lang_lower=lang_lower, id=sid) for sid in sentence_ids]
    return [p for p in paths if p.exists()]

def _open_clip(path: Path):
    """Safely open a clip; return None if ffmpeg chokes or file is corrupt."""
    try:
        return VideoFileClip(str(path))
    except Exception as e:
        print(f"⚠ Skipping {path.name}: {e}")
        return None

def chunk(lst: List[Path], size: int) -> Iterable[List[Path]]:
    for i in range(0, len(lst), size):
        yield lst[i:i + size]

def write_chunk(chap_idx: int, chunk_idx: int, clip_paths: List[Path], lang_lower: str) -> None:
    if not clip_paths:
        return
    clips = []
    for p in clip_paths:
        c = _open_clip(p)
        if c is not None:
            clips.append(c)
    if not clips:
        print(f"⚠ Chapter {chap_idx} chunk {chunk_idx:02d}: all clips unreadable – skipped")
        return

    print(f"▶ Chapter {chap_idx} chunk {chunk_idx:02d}: concatenating {len(clips)} clips …")
    final = concatenate_videoclips(clips, method="compose")

    out_file = OUTPUT_DIR / f"{lang_lower}_chapter_{chap_idx}_chunk_{chunk_idx:02d}.mp4"
    tmp_file = out_file.with_suffix(".tmp.mp4")

    try:
        final.write_videofile(
            str(tmp_file), fps=FPS, codec="libx264", audio_codec="aac",
            threads=FFMPEG_THREADS_PER_JOB,
            ffmpeg_params=["-pix_fmt", "yuv420p", "-movflags", "+faststart"],
            preset="ultrafast", logger=None,
        )
        time.sleep(0.5)  # allow FFmpeg to release file lock
        tmp_file.replace(out_file)
        print(f"✅ {out_file.name} written")
    except Exception as e:
        print(f"❌ Error writing chunk: {e}")
    finally:
        final.close()
        for c in clips:
            c.close()

# ── MAIN ───────────────────────────────────────────────────────────────
def main() -> None:
    random.seed(SHUFFLE_SEED)

    paths = build_paths(LANGUAGE, MODE)
    chapter_map = parse_chapters(paths["sent_txt"])
    if not chapter_map:
        print("⚠ No chapters detected – nothing to do.")
        return

    # --- Chapter selection ---
    if SINGLE_CHAPTER is not None:
        chapter_map = {c: ids for c, ids in chapter_map.items() if c == SINGLE_CHAPTER}
        print(f"✅ Processing only Chapter {SINGLE_CHAPTER}")
    else:
        last_chapter = max(chapter_map)
        start = START_CHAPTER or 1
        end   = END_CHAPTER or last_chapter
        if start > end:
            raise ValueError(f"Invalid chapter range: start {start} > end {end}")
        chapter_map = {c: ids for c, ids in chapter_map.items() if start <= c <= end}
        print(f"✅ Processing Chapters {start}–{end}")

    # --- Process each chapter ---
    for chap_num, sentence_ids in chapter_map.items():
        # Exclude sentences
        sentence_ids = [sid for sid in sentence_ids if sid not in EXCLUDED_SENTENCES]
        if not sentence_ids:
            print(f"⚠ Chapter {chap_num}: all sentences excluded – skipped")
            continue

        clip_paths = gather_clips(sentence_ids, paths["lang_lower"], paths["out_dir"])
        if not clip_paths:
            print(f"⚠ Chapter {chap_num}: no clips found – skipped")
            continue

        if MODE == "homework":
            random.shuffle(clip_paths)

        for chunk_idx, sub in enumerate(chunk(clip_paths, CHUNK_SIZE), start=1):
            write_chunk(chap_num, chunk_idx, sub, paths["lang_lower"])

if __name__ == "__main__":
    main()
