"""
Chapter Video Combiner  • 2025-07-24 (clean version)
────────────────────────────────────────────────────────────────────────────
Stitch the single-sentence videos generated by *multi_language_video_generator.py*
into **multiple videos per chapter**, with options:

1. Process a single chapter only.
2. Process a range of chapters (start–end).
3. Exclude specific sentence IDs.

Export is done in fixed-size chunks (default 10 clips per file):

    nufi_chapter_1_chunk_01.mp4
    nufi_chapter_1_chunk_02.mp4
    …

Robustness:
• Corrupt/missing clips are skipped with a warning (⚠).
• Every VideoFileClip is explicitly closed.

Tested with MoviePy 1.x. For MoviePy 2.x, update the import line as noted.
"""

from __future__ import annotations
import os, random, re, time
from pathlib import Path
from typing import List, Dict, Iterable
from moviepy.editor import VideoFileClip, concatenate_videoclips

import logging
from contextlib import contextmanager

import step0_config as cfg


# from moviepy import VideoFileClip, concatenate_videoclips  # ← for MoviePy 2.x

# ── USER SETTINGS ──────────────────────────────────────────────────────

BASE_DIR = cfg.BASE_DIR

USE_PRIVATE_ASSETS = os.getenv(
    "USE_PRIVATE_ASSETS",
    "1" if getattr(cfg, "USE_PRIVATE_ASSETS", True) else "0"
) == "1"

LANGUAGE = cfg.LANGUAGE.title()
MODE     = cfg.MODE.lower()                      # "lecture" | "homework"

FPS                  = int(getattr(cfg, "FRAME_RATE", 24))
FFMPEG_THREADS_PER_JOB = int(getattr(cfg, "FFMPEG_THREADS", 2))
SHUFFLE_SEED = None
CHUNK_SIZE           = int(getattr(cfg, "CHUNK_SIZE", 10))

# Chapter selection (all optional in cfg)
SINGLE_CHAPTER = getattr(cfg, "SINGLE_CHAPTER", None)
START_CHAPTER  = getattr(cfg, "FILTER_CHAPTER_START", 1)
END_CHAPTER    = getattr(cfg, "FILTER_CHAPTER_END", 32)

# Exclusions
EXCLUDED_SENTENCES = set(getattr(cfg, "EXCLUDED_SENTENCES", set()))

# ─── Asset Source Config ──────────────────────────────────────────────
# USE_PRIVATE_ASSETS = True   # True → private_assets, False → normal assets


# # Check if env variable exists, otherwise set default
# if "USE_PRIVATE_ASSETS" in os.environ:
#     USE_PRIVATE_ASSETS = os.getenv("USE_PRIVATE_ASSETS") == "1"
#     print("using Private Assets from env variable")
# else:
#     print(" Private Assets not found from the env variable")
#     # Local default when not provided by runner
#     USE_PRIVATE_ASSETS = True   # change default if needed


def get_asset_path(relative_path: str) -> Path:
    base = BASE_DIR / ("private_assets" if USE_PRIVATE_ASSETS else "assets")
    return base / relative_path



# ── FOLDER LAYOUT ──────────────────────────────────────────────────────


# Output directory (always created)
# VIDEO_DIR = assets_dir / "Languages" / f"{LANGUAGE.title()}Phrasebook" / "Results_Videos" / f"{MODE.title()}"
VIDEO_DIR = get_asset_path(f"Languages/{LANGUAGE.title()}Phrasebook/Results_Videos/{MODE.title()}")

VIDEO_PATTERN = "{lang_lower}_sentence_{id}.mp4"
OUTPUT_DIR = VIDEO_DIR / f"{LANGUAGE.title()}_Chapters_Combined"

OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
# os.makedirs(OUTPUT_DIR, exist_ok=True)

# ── LOGGING CONFIG ──────────────────────────────────────────────────────
# assets_dir = BASE_DIR / "assets"
# LOG_DIR = assets_dir / "Languages" / f"{LANGUAGE.title()}Phrasebook"/"Logs"
# LOG_DIR.mkdir(parents=True, exist_ok=True)

LOG_DIR = get_asset_path(f"Languages/{LANGUAGE.title()}Phrasebook/Logs")
LOG_DIR.mkdir(parents=True, exist_ok=True)


SENTENCES_PATH = get_asset_path(f"Languages/{LANGUAGE.title()}Phrasebook/{LANGUAGE.lower()}_english_french_phrasebook_sentences_list.txt")

# Use the script name but place it inside the Phrasebook folder
log_file = LOG_DIR / Path(__file__).with_suffix(".log").name

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%H:%M:%S",
    handlers=[
        logging.FileHandler(log_file, mode="w", encoding="utf-8"),
        logging.StreamHandler()
    ]
)


def format_elapsed(seconds: float) -> str:
    if seconds < 60:
        return f"{seconds:.2f} sec"
    elif seconds < 3600:
        return f"{seconds/60:.2f} min"
    elif seconds < 86400:
        return f"{seconds/3600:.2f} hr"
    else:
        return f"{seconds/86400:.2f} days"

@contextmanager
def log_time(step_name: str):
    start = time.perf_counter()
    logging.info(f"▶️ Starting {step_name}…")
    try:
        yield
    finally:
        elapsed = time.perf_counter() - start
        logging.info(f"⏱ Finished {step_name} in {format_elapsed(elapsed)}")

        
# ── HELPERS ────────────────────────────────────────────────────────────

def parse_chapters(txt_file: Path) -> Dict[int, List[int]]:
    """Return {chapter_number: [sentence_id,…]} preserving original order."""
    chapters: Dict[int, List[int]] = {}
    current = None
    with open(txt_file, encoding="utf-8") as fh:
        for ln in fh:
            if "|" not in ln:
                continue
            try:
                id_part, en_raw = ln.split(")", 1)
                sid = int(id_part.strip())
            except ValueError:
                continue
            english = en_raw.split("|", 1)[0].strip().lower()
            if english.startswith("chapter"):
                m = re.search(r"chapter\s+(\d+)", english)
                current = int(m.group(1)) if m else (current or 0) + 1
            if current is None:
                continue
            chapters.setdefault(current, []).append(sid)
    return chapters


def gather_clips(sentence_ids: Iterable[int]) -> List[Path]:
    paths = [VIDEO_DIR / VIDEO_PATTERN.format(lang_lower=LANGUAGE.lower(), id=sid) for sid in sentence_ids]
    return [p for p in paths if p.exists()]

def _open_clip(path: Path):
    """Safely open a clip; return None if ffmpeg chokes or file is corrupt."""
    try:
        return VideoFileClip(str(path))
    except Exception as e:
        print(f"⚠ Skipping {path.name}: {e}")
        return None

def chunk(lst: List[Path], size: int) -> Iterable[List[Path]]:
    for i in range(0, len(lst), size):
        yield lst[i:i + size]

def write_chunk(chap_idx: int, chunk_idx: int, clip_paths: List[Path]) -> None:
    if not clip_paths:
        return
    clips = []
    for p in clip_paths:
        c = _open_clip(p)
        if c is not None:
            clips.append(c)
    if not clips:
        print(f"⚠ Chapter {chap_idx} chunk {chunk_idx:02d}: all clips unreadable – skipped")
        return

    print(f"▶ Chapter {chap_idx} chunk {chunk_idx:02d}: concatenating {len(clips)} clips …")
    final = concatenate_videoclips(clips, method="compose")

    out_file = OUTPUT_DIR / f"{LANGUAGE.lower()}_chapter_{chap_idx}_chunk_{chunk_idx:02d}.mp4"
    tmp_file = out_file.with_suffix(".tmp.mp4")

    try:
        final.write_videofile(
            str(tmp_file), fps=FPS, codec="libx264", audio_codec="aac",
            threads=FFMPEG_THREADS_PER_JOB,
            ffmpeg_params=["-pix_fmt", "yuv420p", "-movflags", "+faststart"],
            preset="ultrafast", logger=None,
        )
        time.sleep(0.5)  # allow FFmpeg to release file lock
        tmp_file.replace(out_file)
        print(f"✅ {out_file.name} written")
    except Exception as e:
        print(f"❌ Error writing chunk: {e}")
    finally:
        final.close()
        for c in clips:
            c.close()

# ── MAIN ───────────────────────────────────────────────────────────────

def main() -> None:
    random.seed(SHUFFLE_SEED)

    with log_time("Chapter Combiner"):
        chapter_map = parse_chapters(SENTENCES_PATH)
        if not chapter_map:
            print("⚠ No chapters detected – nothing to do.")
            return

        # --- Chapter selection ---
        if SINGLE_CHAPTER is not None:
            chapter_map = {c: ids for c, ids in chapter_map.items() if c == SINGLE_CHAPTER}
            print(f"✅ Processing only Chapter {SINGLE_CHAPTER}")
        else:
            last_chapter = max(chapter_map)
            start = START_CHAPTER or 1
            end   = END_CHAPTER or last_chapter
            if start > end:
                raise ValueError(f"Invalid chapter range: start {start} > end {end}")
            chapter_map = {c: ids for c, ids in chapter_map.items() if start <= c <= end}
            print(f"✅ Processing Chapters {start}–{end}")

        # --- Process each chapter ---
        for chap_num, sentence_ids in chapter_map.items():
            with log_time(f"Chapter {chap_num}"):
                # Exclude sentences
                sentence_ids = [sid for sid in sentence_ids if sid not in EXCLUDED_SENTENCES]
                if not sentence_ids:
                    print(f"⚠ Chapter {chap_num}: all sentences excluded – skipped")
                    continue

                clip_paths = gather_clips(sentence_ids)
                if not clip_paths:
                    print(f"⚠ Chapter {chap_num}: no clips found – skipped")
                    continue

                if MODE == "homework":
                    random.shuffle(clip_paths)

                for chunk_idx, sub in enumerate(chunk(clip_paths, CHUNK_SIZE), start=1):
                    with log_time(f"Chapter {chap_num} chunk {chunk_idx}"):
                        write_chunk(chap_num, chunk_idx, sub)

if __name__ == "__main__":
    main()
